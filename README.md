# Fibonacci Sequence in CUDA 

This repository contains a Python script demonstrating the computation of the Fibonacci sequence using a CUDA kernel within a Google Colaboratory environment. It also includes a simple sequential Python implementation for performance comparison.

## Overview

The Fibonacci sequence is a series where each number is the sum of the two preceding ones, typically starting with 0 and 1. This repository explores how to parallelize this computation using NVIDIA's CUDA architecture through the Numba library in Python.

The script includes:

* A CUDA kernel (`fibonacci_cuda_kernel`) designed to compute Fibonacci numbers in parallel on the GPU.
* A Python function (`fibonacci_cuda`) to manage GPU memory allocation and launch the CUDA kernel.
* A standard sequential Python function (`fibonacci_sequential`) for calculating the Fibonacci sequence on the CPU.
* A main execution block that compares the execution time of both implementations for a given number of Fibonacci numbers (default: 220).
* Error handling for cases where a CUDA-enabled GPU or compatible drivers are not available.
* Basic performance observation for the given problem size.

**Note:** This example is primarily intended for demonstration within a Google Colab environment, which has pre-configured drivers and libraries. Compatibility with specific CUDA driver versions in Colab can sometimes be an issue, as highlighted in the comments and code.

## Getting Started

1.  **Open in Google Colab:** The easiest way to run this code is to open the `fibonacci_cuda_colab.ipynb` (or the `.py` script if you save it as such) directly in Google Colaboratory. You can upload it to your Google Drive and then open it with Colab.

2.  **Install Dependencies (Run the first cell):** The Colab notebook (or your Python environment) might require the Numba library for CUDA support and NumPy for array handling. The following commands are included in the notebook to install specific older versions that might have better compatibility with Colab's CUDA drivers:

    ```python
    !pip install numba==0.57.0
    !pip install llvmlite==0.40.1
    !pip install numpy==1.24.4
    ```

3.  **Restart Runtime (Crucial):** After running the installation cell, you **must** restart the Colab runtime by going to `Runtime` in the menu and clicking `Restart runtime`. This ensures that the newly installed library versions are used.

4.  **Run All Cells:** Execute the remaining cells in the notebook to run the sequential and CUDA Fibonacci computations and see the performance comparison.

## Observations

For a relatively small number of elements (e.g., N = 220), you might observe that the sequential implementation is faster or has a similar execution time to the CUDA implementation. This is often due to the overhead of transferring data to and from the GPU and the kernel launch time outweighing the benefits of parallelism for small tasks.

As the value of N increases significantly, the potential benefits of the parallel CUDA implementation might become more apparent, assuming compatibility with the CUDA drivers is resolved.

The current CUDA kernel implementation has data dependencies between threads, which can limit the achievable parallelism for this specific problem. More advanced CUDA techniques could be explored for further optimization.

## Potential Issues and Troubleshooting

* **`CUDAError: CUDA driver library cannot be found.`**: This indicates that a CUDA-enabled GPU or the necessary drivers are not available in your environment. Ensure you have selected a GPU runtime in Google Colab (`Runtime > Change runtime type > GPU`).
* **`CUDA_ERROR_UNSUPPORTED_PTX_VERSION`**: This error suggests an incompatibility between the PTX (Parallel Thread Execution) code generated by Numba and the CUDA driver installed in your Colab environment. This is a common issue in Colab due to pre-configured environments. Trying older versions of Numba and llvmlite (as shown in the installation steps) might help, but there's no guarantee.
* **`NameError: name 'cuda' is not defined`**: Ensure you have the line `from numba import cuda` in your script after installing and restarting the runtime.

## Contributing

Contributions to this repository are welcome. Feel free to submit pull requests with improvements or bug fixes.
